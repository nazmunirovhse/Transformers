{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNWxK_a7UpfW"
      },
      "source": [
        "## Трансформеры"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные - https://drive.google.com/file/d/1te0QzJB6SNppduuMVcTcxncqudMxRaPi/view?usp=sharing"
      ],
      "metadata": {
        "id": "FhlDLrTYaaix"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4lYBJSP8Upfd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import time\n",
        "import tqdm\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "\n",
        "random.seed(123)\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqp5o8p-Upfh"
      },
      "source": [
        "Модель будет предсказывать следующую букву, которая должна идти в последовательности. Такие языковые модели применяются в распозновании речи, так как предоставляют дополнительную информацию акустической модели при выборе следующего символа."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huuG2fEEaOBz",
        "outputId": "bd543140-95b2-42cc-d7e9-5818b7698ce0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWfOXPvbUpfi",
        "outputId": "4857d29e-1604-4a7e-c9f8-496292d349a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/small_corp_for_test.txt'\n",
        "file = open(path, 'r')\n",
        "data = file.readlines()\n",
        "file.close()\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_letters = np.sum(list(map(lambda x: len(x), data))) # всего символов \n",
        "sum_of_letters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS1PDOaTulyZ",
        "outputId": "d9d33c6f-7b0a-474e-d545-68c7acd3845c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30576062"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_text = ''.join(data)\n",
        "\n",
        "chars = tuple(set(joined_text)) \n",
        "\n",
        "print(chars, len(chars)) # вывожу символы и их количество"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6oNLMQ_uw2y",
        "outputId": "b7fa0680-c515-4a7b-834c-6f8f6a93802b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ц', 'ь', 'р', 'о', '[', 'ч', 'б', 'ё', 'п', 'ю', 'е', 'м', 'н', 'в', 'й', 'ы', 'я', 'у', 'ж', 'ъ', 'щ', 'ш', ']', 'ф', 'д', 'г', 'к', 'с', 'л', 'т', 'э', 'х', 'а', 'и', 'з', '-') 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "malO1VoUUpfj",
        "outputId": "ab0bf018-8cfe-48ed-d459-498368d9ce03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[добро]',\n",
              " '[кого]',\n",
              " '[капитан]',\n",
              " '[нет]',\n",
              " '[зачем]',\n",
              " '[чтопроисходит]',\n",
              " '[чтотакое]',\n",
              " '[рассказ]',\n",
              " '[никому]',\n",
              " '[нучто]']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "data = [item.replace('\\n', '') for item in data]\n",
        "data = [item.replace(' ', '') for item in data]\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_of_letters = np.sum(list(map(lambda x: len(x), data))) # всего символов \n",
        "sum_of_letters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqtMAvw-p9Vy",
        "outputId": "2ea6f1b1-e8c5-4f8f-fe4c-c3e34db7eaef"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26895842"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_text = ''.join(data)\n",
        "\n",
        "chars = tuple(set(joined_text)) \n",
        "\n",
        "print(chars, len(chars)) # вывожу символы и их количество"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ20BV5tmVY0",
        "outputId": "b55700ab-ac9d-41cc-c5d9-4c77620297a9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ц', 'ь', 'р', 'о', '[', 'ч', 'б', 'ё', 'п', 'ю', 'е', 'м', 'н', 'в', 'й', 'ы', 'я', 'у', 'ж', 'ъ', 'щ', 'ш', ']', 'ф', 'д', 'г', 'к', 'с', 'л', 'т', 'э', 'х', 'а', 'и', 'з', '-') 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk_CbyHpUpfk"
      },
      "source": [
        "### Подготовка текста "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-HBSqNzpUpfk"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self):\n",
        "        self.alphabet = '_добсркгаупитнезчмфяжлйвцыэь-шхющёъ][ '\n",
        "        self.token2ind = {}\n",
        "        self.ind2token = {}\n",
        "        for i in range(len(self.alphabet)):\n",
        "            self.token2ind[self.alphabet[i]] = i\n",
        "            self.ind2token[i] = self.alphabet[i]\n",
        "        \n",
        "    \n",
        "    def preprocess(self, text, window_size):\n",
        "        \n",
        "        pad = [0]\n",
        "        if type(text) == list:\n",
        "          text = ' '.join(text)\n",
        "        pad_number = window_size - len(text) + 1 # количество символов pad для текста\n",
        "        text = text.lower() \n",
        "        token_text = (list(map(lambda x: self.token2ind[x], text))) # заменяю все символы в тексте на индексы\n",
        "        return ([37] + token_text[1:-2] + [36] + pad_number*pad ), ([37] + token_text[2:-1] + [36] + pad_number*pad) # массивы без первой  и полседней букв"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xAsZ59QGUpfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a202cce4-09ce-4e47-c0b5-6c4dc30ccbd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[[добро]]',\n",
              " '[[кого]]',\n",
              " '[[капитан]]',\n",
              " '[[нет]]',\n",
              " '[[зачем]]',\n",
              " '[[чтопроисходит]]',\n",
              " '[[чтотакое]]',\n",
              " '[[рассказ]]',\n",
              " '[[никому]]',\n",
              " '[[нучто]]']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "data = list(map(lambda x: \"[\" + x + \"]\", data)) # дополняю скобками\n",
        "\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCeGQDKiUpfm"
      },
      "source": [
        "### Подготовка текста для обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5tj3Vb3rUpfm"
      },
      "outputs": [],
      "source": [
        "THRESHOLD = 128 # задаю порог\n",
        "\n",
        "beg_thre = [] \n",
        "for text in data:\n",
        "  if len(text) <= THRESHOLD: \n",
        "    beg_thre.append(text)  # добавляю только тексты которые прошли порог\n",
        "\n",
        "random.shuffle(beg_thre) # перемешиваю данные\n",
        "\n",
        "train = np.array(beg_thre[:np.round(len(beg_thre) * 0.85).astype(int)]) # определяю тренировочную выборку\n",
        "\n",
        "test = np.array(beg_thre[np.round(len(beg_thre) * 0.85).astype(int):]) # определяю тестовую выборку"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXz3UnMJMoFx",
        "outputId": "befd5153-43f0-4bf7-eec2-578f2ae89b15"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "586249"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96KpZWJhMqGE",
        "outputId": "006a4852-b439-4d6f-93ba-e91c170ba26e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103456"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(beg_thre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8sLTh0FXfmA",
        "outputId": "6c3a1453-7b6c-492e-e051-ade4bc4675af"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "689705"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu_hO6HTUpfm"
      },
      "source": [
        "### Класс Dataset для обработки данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "h5WSHSl5Upfm"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, x, preproc, win_size = 128):\n",
        "      self.x = x\n",
        "      self.preproc = preproc\n",
        "      self.win_size = win_size\n",
        "    \n",
        "    def __len__(self):\n",
        "    \n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x, y = self.preproc.preprocess(self.x[idx], self.win_size) \n",
        "        x = torch.LongTensor(x) # отдельно перевожу массив по которому нужно предсказать\n",
        "        y = torch.LongTensor(y) # отдельно перевожу массив который нужно предсказать\n",
        "        \n",
        "        return x, y\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "FgVIPRtvUpfn"
      },
      "outputs": [],
      "source": [
        "preproc = Preprocessor()\n",
        "train_dataset = TextDataset(train, preproc)\n",
        "test_dataset = TextDataset(test, preproc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiWuHD9IYmOm",
        "outputId": "c8c61318-5865-4742-de39-04b3fde79ad1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([37, 36, 16, 12,  2,  3, 25, 15,  8, 10, 11,  4, 27, 36,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0]),\n",
              " tensor([37, 16, 12,  2,  3, 25, 15,  8, 10, 11,  4, 27, 35, 36,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHI24Si_Upfn"
      },
      "source": [
        "### Класс модели"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Маскирование символов нобходимо для того, чтобы модель лучше обучалась, выбирая случайные буквы. \n"
      ],
      "metadata": {
        "id": "WzdEVP0VsQja"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0uKEHHdBUpfo"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "STlHpVTXUpfo"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size,\n",
        "                  nhead = 8,\n",
        "                  num_layers = 6,\n",
        "                  dropout = 0.1):\n",
        "        super(LanguageModel, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, 32, padding_idx=0)\n",
        "        self.pe = PositionalEncoding(32, dropout)\n",
        "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(32, nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers)\n",
        "        self.decoder = nn.Sequential(nn.Linear(32, 64),\n",
        "                                     nn.ReLU(),\n",
        "                                     nn.Linear(64, vocab_size))\n",
        "        \n",
        "        #nn.TransformerDecoder(nn.TransformerDecoderLayer(32, nhead), num_layers)\n",
        "    \n",
        "    def forward(self, x, src_mask):\n",
        "\n",
        "        x = self.pe.forward(self.emb(x))\n",
        "        x = x.transpose(1, 0)\n",
        "        x = self.transformer_encoder(x, src_mask)\n",
        "        x = self.decoder(x)\n",
        "        return x.transpose(1, 0)\n",
        "    \n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "palXEpUAUpfo"
      },
      "outputs": [],
      "source": [
        "model = LanguageModel(vocab_size = len('_добсркгаупитнезчмфяжлйвцыэь-шхющёъ][ '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIozjl-nUpfp"
      },
      "source": [
        "### Класс для обучения и валидации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "v7Y4AGSfUpfp"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, train_dataset, test_dataset):\n",
        "        \n",
        "        self.model = model\n",
        "        \n",
        "        self.train_batch_size = 64\n",
        "        self.test_batch_size = 64\n",
        "        \n",
        "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                                            batch_size=self.train_batch_size,\n",
        "                                                            shuffle=False, \n",
        "                                                            num_workers=1)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
        "                                                            batch_size=self.test_batch_size,\n",
        "                                                            shuffle=False, \n",
        "                                                            num_workers=1)\n",
        "        self.train_dataloader_size = len(self.train_dataloader)\n",
        "        self.test_dataloader_size = len(self.test_dataloader)\n",
        "\n",
        "        self.device = 'cuda:0'\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index = 0)\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        \n",
        "        self.steps_to_print = 1000\n",
        "        \n",
        "    def train_one_epoch(self, epoch_number):\n",
        "        step = 0\n",
        "        counted_loss = 0\n",
        "        current_time = time.time()\n",
        "        it = 0\n",
        "        \n",
        "        model = self.model.to(self.device)\n",
        "        \n",
        "        for batch in self.train_dataloader:\n",
        "          \n",
        "            x, y = batch\n",
        "\n",
        "            x, y = x.to(self.device), y.to(self.device)\n",
        "            \n",
        "            src_mask = self.model.generate_square_subsequent_mask(128).to(self.device)\n",
        "            predicted = self.model(x, src_mask)\n",
        "            predicted = torch.reshape(predicted, (predicted.shape[0]*128, 38))\n",
        "            y = y.flatten()\n",
        "            \n",
        "            loss = self.criterion(predicted, y)\n",
        "            counted_loss = loss\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            step += 1\n",
        "            it += 1\n",
        "\n",
        "            if step%self.steps_to_print == 0:\n",
        "                result = 'Train epoch '+str(epoch_number)+' | '\n",
        "                result += 'Step '+str(step)+'/'+str(self.train_dataloader_size)+' | '\n",
        "                result += 'Counted loss '+str(counted_loss)+' | '\n",
        "                result += 'ppl '+str(math.exp(counted_loss/it))+' | '\n",
        "                result += 'time '+str(time.time() - current_time) + ' | '\n",
        "                print(result)\n",
        "                current_time = time.time()\n",
        "                counted_loss = 0\n",
        "                it = 0\n",
        "  \n",
        "    def validate_one_epoch(self, epoch_number):\n",
        "        step = 0\n",
        "        counted_loss = 0\n",
        "        current_time = time.time()\n",
        "        it = 0\n",
        "\n",
        "        for batch in self.test_dataloader:\n",
        "            it+=1\n",
        "            step+=1\n",
        "            \n",
        "            x, y = batch\n",
        "            x, y = x.to(self.device), y.to(self.device)\n",
        "\n",
        "            src_mask = self.model.generate_square_subsequent_mask(128).to(self.device)\n",
        "            \n",
        "            predicted = self.model(x, src_mask)\n",
        "            predicted = torch.reshape(predicted, (predicted.shape[0]*128, 38))\n",
        "            y = y.flatten()\n",
        "            loss = self.criterion(predicted, y)\n",
        "            counted_loss = loss\n",
        "      \n",
        "            if step%(self.steps_to_print//2) == 0:\n",
        "                result = 'Validate epoch '+str(epoch_number)+' | '\n",
        "                result += 'Step '+str(step)+'/'+str(self.test_dataloader_size)+' | '\n",
        "                result += 'Counted loss '+str(counted_loss)+' | '\n",
        "                result += 'ppl '+str(math.exp(counted_loss/it))+' | '\n",
        "                result += 'time '+str(time.time() - current_time) + ' | '\n",
        "                print(result)\n",
        "                current_time = time.time()\n",
        "                counted_loss = 0\n",
        "                it = 0\n",
        "        \n",
        "    def train(self, number_of_epochs):\n",
        "        for epoch in range(0, number_of_epochs):\n",
        "            self.model.train\n",
        "            self.train_one_epoch(epoch)\n",
        "            with torch.no_grad():\n",
        "                self.model.eval()\n",
        "                self.validate_one_epoch(epoch)\n",
        "            print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_dUgf78Upfp"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "_JjKCKMLUpfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09489a0e-131b-4f25-9fb3-e81105854e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch 0 | Step 1000/9161 | Counted loss tensor(2.4876, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0024907459764503 | time 69.46962141990662 | \n",
            "Train epoch 0 | Step 2000/9161 | Counted loss tensor(2.3590, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0023618264395462 | time 69.27170610427856 | \n",
            "Train epoch 0 | Step 3000/9161 | Counted loss tensor(2.1874, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0021897617955957 | time 69.3695867061615 | \n",
            "Train epoch 0 | Step 4000/9161 | Counted loss tensor(2.0980, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0021002108844317 | time 69.49207878112793 | \n",
            "Train epoch 0 | Step 5000/9161 | Counted loss tensor(2.0432, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0020452653829692 | time 69.05400657653809 | \n",
            "Train epoch 0 | Step 6000/9161 | Counted loss tensor(2.0108, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0020128175924568 | time 69.18538451194763 | \n",
            "Train epoch 0 | Step 7000/9161 | Counted loss tensor(1.9997, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0020017371039787 | time 69.26280379295349 | \n",
            "Train epoch 0 | Step 8000/9161 | Counted loss tensor(2.0255, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0020275160220833 | time 69.287677526474 | \n",
            "Train epoch 0 | Step 9000/9161 | Counted loss tensor(1.9479, device='cuda:0', grad_fn=<NllLossBackward0>) | ppl 1.0019497963376862 | time 69.09003591537476 | \n",
            "Validate epoch 0 | Step 500/1617 | Counted loss tensor(1.7485, device='cuda:0') | ppl 1.0035032144812746 | time 10.623932838439941 | \n",
            "Validate epoch 0 | Step 1000/1617 | Counted loss tensor(1.7075, device='cuda:0') | ppl 1.0034208129176574 | time 10.556087970733643 | \n",
            "Validate epoch 0 | Step 1500/1617 | Counted loss tensor(1.6574, device='cuda:0') | ppl 1.0033202141539677 | time 10.544536828994751 | \n",
            "\n"
          ]
        }
      ],
      "source": [
        "model= Trainer(model, train_dataset, test_dataset)\n",
        "\n",
        "model.train(number_of_epochs = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MPcn0606gFGD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Munirov_Nazim_hw3_iad5 (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}